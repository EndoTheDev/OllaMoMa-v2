# OllaMoMa v2

> A modern web interface for interacting with Ollama models, built with Nuxt 3 and Nuxt UI v3.
>
> âš ï¸ **Work in Progress**: This project is under active development.

## ğŸŒŸ Features

- ğŸ¨ Interactive Chat Interface
  - Real-time streaming responses
  - Multiple model support
  - Clear conversation history
- ğŸ¤– Model Management
  - View and manage Ollama models
  - Search and sort functionality
  - Detailed model information
- ğŸ¨ Modern UI with Nuxt UI v3
  - Dark/Light mode with theme customization
  - Responsive design for all devices
  - Customizable UI elements
- âš¡ Performance Focused
  - Fast and responsive interface
  - Efficient model handling
  - Type-safe development

## ğŸ› ï¸ Tech Stack

- **Frontend Framework**: [Nuxt 3](https://nuxt.com/)
- **UI Components**: [Nuxt UI v3](https://ui.nuxt.com/)
- **Styling**: [Tailwind CSS](https://tailwindcss.com/)
- **State Management**: [Pinia](https://pinia.vuejs.org/)
- **Utilities**: [VueUse](https://vueuse.org/)
- **LLM Backend**: [Ollama](https://ollama.ai/)

## ğŸ“‹ Prerequisites

Before you begin, ensure you have:
- Node.js (v18+)
- Ollama installed and running locally
- Git for version control
- Docker (optional, for containerized deployment)

## ğŸš€ Quick Start

### Local Development

1. **Clone and Install**
   ```bash
   git clone https://github.com/EndoTheDev/OllaMoMa-v2.git
   cd OllaMoMa-v2
   npm install  # or pnpm install / yarn install / bun install
   ```

2. **Start Development Server**
   ```bash
   npm run dev  # or pnpm dev / yarn dev / bun run dev
   ```

3. **Configure Ollama**
   - Default settings: host: 127.0.0.1, port: 11434
   - Adjust in application settings if needed

### Docker Deployment

1. **Using Docker**
   ```bash
   # Build the image
   docker build -t ollamoma-v2 .
   
   # Run the container
   docker run -d -p 3000:3000 --name ollamoma ollamoma-v2
   ```

2. **Using Docker Compose**
   ```bash
   # Start the application
   docker compose up -d
   
   # Stop the application
   docker compose down
   ```

3. **Important Docker Notes**
   - Ensure Ollama is running on your host machine
   - For Windows/macOS: Use `host.docker.internal` instead of `localhost`
   - For Linux: Use your host machine's IP address

## ğŸ“š Documentation

Detailed documentation is available in the [docs](./docs) directory:

- **Getting Started**
  - [Installation Guide](./docs/getting-started/installation.md)
  - [Development Guide](./docs/getting-started/development.md)

- **Features**
  - [Chat Interface](./docs/pages/index.md)
  - [Model Management](./docs/pages/models.md)
  - [Settings](./docs/pages/settings.md)

## ğŸ—ï¸ Project Structure

```
.
â”œâ”€â”€ assets/          # Static assets
â”œâ”€â”€ components/      # Vue components
â”œâ”€â”€ composables/     # Vue composables
â”œâ”€â”€ docs/           # Documentation
â”œâ”€â”€ pages/          # File-based routing
â”œâ”€â”€ server/         # Server API routes
â”œâ”€â”€ stores/         # Pinia stores
â”œâ”€â”€ tests/          # Test files
â””â”€â”€ types/          # TypeScript types
```

## ğŸ“ Roadmap

### Current Progress
- âœ… Core Features
  - âœ… Chat interface with streaming
  - âœ… Model management
  - âœ… Theme customization
  - âœ… Settings management

### Upcoming Features
- ğŸ”„ LangChain integration
- ğŸ“Š Knowledge graph visualization
- ğŸ¨ Enhanced theme customization
  - Color picker
  - Border radius settings
- ğŸ—ƒï¸ Database/Files management

## ğŸ¤ Contributing

We welcome contributions! Please see our [Development Guide](./docs/getting-started/development.md) for details on:
- Setting up your development environment
- Our coding standards
- The contribution workflow
- Testing requirements

## ğŸ“„ License

This project is licensed under the MIT License.

---
Built with â¤ï¸ by EndoTheDev using [Nuxt 3](https://nuxt.com/) and [Nuxt UI v3](https://ui.nuxt.com/)
